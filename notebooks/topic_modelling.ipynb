{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting tools\n",
    "gensim\n",
    "from tqdm import tqdm\n",
    "import pyLDAvis\n",
    "# import pyLDAvis.gensim  # don't skip this\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/anshu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'covid', 'vaccine', 'vaccination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tw_stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mv/c151lb7j7xx6ff_q9_85p_pc0000gn/T/ipykernel_98437/1116804865.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtw_stopwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tw_stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words.extend(tw_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "187"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_stopwords = []\n",
    "f = open('data/stopwords.txt', 'r')\n",
    "for line in f.readlines():\n",
    "    tw_stopwords.append(line.rstrip('\\n'))\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/Users/anshu/Work/Code/rpm-v2/data/v2/'\n",
    "\n",
    "sg_tweets = pd.read_csv(BASE_PATH + \"sg.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweet_text', 'tweet_time', 'tweet_id', 'tweet_lang',\n",
       "       'tweet_possibly_sensitive', 'entity_image_url', 'entity_mentions',\n",
       "       'entity_hashtags', 'entity_link_url', 'user_id_x', 'user_name_x',\n",
       "       'user_screenname_x', 'user_friends_count', 'user_followers_count',\n",
       "       'user_verified', 'user_location', 'user_desc', 'user_geo_coding',\n",
       "       'user_geo_tagging', 'user_id_y', 'user_name_y', 'user_screenname_y',\n",
       "       'tweet_enagagement_type', 'replied_to_tweet_id', 'replied_to_user_id',\n",
       "       'replied_to_user_screenname', 'retweeted_tweet_id',\n",
       "       'retweeted_tweet_time', 'retweeted_user_id', 'retweeted_user_name',\n",
       "       'retweeted_user_verified', 'retweeted_user_screenname',\n",
       "       'retweeted_user_geo_coding', 'retweeted_user_geo_coding_type',\n",
       "       'retweeted_retweet_count', 'retweeted_favorite_count',\n",
       "       'quoted_tweet_text', 'quoted_tweet_id', 'quoted_tweet_time',\n",
       "       'quoted_user_id', 'quoted_user_name', 'quoted_user_verified',\n",
       "       'quoted_user_screenname', 'quoted_user_geo_coding',\n",
       "       'quoted_user_geo_coding_type', 'quoted_retweet_count',\n",
       "       'quoted_favorite_count', 'tweet_datetime', 'tweet_date',\n",
       "       'processed_tweet_text', 'processed_quoted_tweet_text',\n",
       "       'tweet_sentiment', 'quoted_tweet_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158949, 54)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influential \n",
    "\n",
    "top_50 = [\n",
    "     'ChannelNewsAsia',\n",
    "     'MothershipSG',\n",
    "     'straits_times',\n",
    "     'TODAYonline',\n",
    "     'STForeignDesk',\n",
    "     'JustinOngTODAY',\n",
    "     'leehsienloong',\n",
    "     'kixes',\n",
    "     'lustfuldesirer',\n",
    "     'historyogi',\n",
    "     'CherylLinCNA',\n",
    "     'sporeMOH',\n",
    "     'Tan_Hui_Yee',\n",
    "     'VivianBala',\n",
    "     'VP',\n",
    "     'muttons',\n",
    "     'AqilHaziqCNA',\n",
    "     'LinXuelingCNA',\n",
    "     'AlifAmsyarCNA',\n",
    "     'gayaCNA',\n",
    "     'PichayadaCNA',\n",
    "     'HweeMinCNA',\n",
    "     'DrSasa22222',\n",
    "     'JoakimGomez',\n",
    "     'xavierlur',\n",
    "     'raaaaachel',\n",
    "     'audreytrp',\n",
    "     'LeongWaiKitCNA'\n",
    "]\n",
    "#  'business',\n",
    "#  'GraceYeohCNA',\n",
    "#  'tzehern_',\n",
    "#  'in_transitiverb',\n",
    "#  'sushibeepbeep',\n",
    "#  'gabriellamarrie',\n",
    "#  'TostevinM',\n",
    "#  'brian2grimey',\n",
    "#  'ialsocruise',\n",
    "#  '0764mg',\n",
    "#  '2021Revtweets',\n",
    "#  'jwlltn',\n",
    "#  'RvlBurma2',\n",
    "#  'cryptocom',\n",
    "#  'mrbrown',\n",
    "#  'shafiur',\n",
    "#  'EdgeFunManager',\n",
    "#  'govsingapore',\n",
    "#  'IrrawaddyNews',\n",
    "#  'EricTopol',\n",
    "#  'deweysim',\n",
    "#  'OutWithMehh',\n",
    "#  'shakiraIaw',\n",
    "#  'jbhavan',\n",
    "#  'DGHisham',\n",
    "#  'SaveMM99',\n",
    "#  'lukeyism',\n",
    "#  'cz_binance',\n",
    "#  'AlifSykes_',\n",
    "#  'STopinion',\n",
    "#  'joannamont',\n",
    "#  'Myanmar_Now_Eng',\n",
    "#  'Monsta_Infinite',\n",
    "#  'foreheadfatty',\n",
    "#  'hidzdotfm',\n",
    "#  'lim_jialiang',\n",
    "#  'march_cmu1',\n",
    "#  'rohini_mohan',\n",
    "#  'Vishalsiddu1',\n",
    "#  'Reuters',\n",
    "#  'thinzashunleiyi',\n",
    "#  'narendramodi',\n",
    "#  'aemieruls_',\n",
    "#  'YahooSG',\n",
    "#  'Kokilaparvathi',\n",
    "#  'soompi',\n",
    "#  'teamsamgaypore',\n",
    "#  'LeeDam18102',\n",
    "#  'stbusinessdesk',\n",
    "#  'muftimenk',\n",
    "#  'seehaojun',\n",
    "#  'hahazebr4',\n",
    "#  'NadiaDaeng',\n",
    "#  'AfifahShameemah',\n",
    "#  'trixieaaang',\n",
    "#  'TaufiqHanafi91',\n",
    "#  'shairacagulada',\n",
    "#  'acertainjolene',\n",
    "#  'Jaarfuckingvis',\n",
    "#  'asonofapeach',\n",
    "#  'PostCultRev',\n",
    "#  'HausofHilton',\n",
    "#  'H0NEYBIX',\n",
    "#  'iwanqais',\n",
    "#  'RedWhiteBlueDot',\n",
    "#  'spring21MM',\n",
    "#  'IamAjak',\n",
    "#  'DrEricDing',\n",
    "#  'nuffsaidny',\n",
    "#  'heybentan',\n",
    "#  'awarenews',\n",
    "#  'Josh12549585',\n",
    "#  'sgcafeevents',\n",
    "#  'iraadnan_',\n",
    "#  'bewithviolet',\n",
    "#  'ActivismCrisis',\n",
    "#  'SCMPNews',\n",
    "#  'STsportsdesk',\n",
    "#  'MayWongCNA',\n",
    "#  'hotgirlzizek',\n",
    "#  'jalaladdinnush',\n",
    "#  'malissaali',\n",
    "#  'maxy_chan16',\n",
    "#  'ST_LifeTweets',\n",
    "#  'WuBlockchain',\n",
    "#  'LyaHaru',\n",
    "#  'cuckaru',\n",
    "#  'KenRoth',\n",
    "#  'BusinessTimes',\n",
    "#  'MizzimaNews',\n",
    "#  'ahbejeremy_',\n",
    "#  'KKMPutrajaya',\n",
    "#  'BBCWorld',\n",
    "#  'TwitterSG',\n",
    "#  'ExathAIO',\n",
    "#  'samaritansofsg',\n",
    "#  'Varanussalvator',\n",
    "#  'sadtextforyou',\n",
    "#  'agonyoferos',\n",
    "#  'lupcheong',\n",
    "#  'JaniceLimTODAY',\n",
    "#  'bhonekhant247',\n",
    "#  'MoreDaysWithU',\n",
    "#  'SenToday',\n",
    "#  'teo_kai_xiang',\n",
    "#  'ConorHaloReach',\n",
    "#  'NDBurma',\n",
    "#  'sgxposed',\n",
    "#  'AdamMGrant',\n",
    "#  'vitariesocks',\n",
    "#  'cvdom2021',\n",
    "#  'speechleyish',\n",
    "#  'afa_singapore',\n",
    "#  'deannagmcdonald',\n",
    "#  'coinhako',\n",
    "#  'HeyMaliniK',\n",
    "#  'nytimes',\n",
    "#  'CyberCSIS',\n",
    "#  'eos_geodesy',\n",
    "#  'SG_Internet',\n",
    "#  'morningKall',\n",
    "#  'princejetsy',\n",
    "#  'NTUsg',\n",
    "#  'muhdnajib103',\n",
    "#  'syoogas',\n",
    "#  'samdylanfinch',\n",
    "#  'eos_rs',\n",
    "#  'AudiKhalid',\n",
    "#  'dk',\n",
    "#  'b3rry_y',\n",
    "#  'roadscholarz',\n",
    "#  'theshadowskank',\n",
    "#  'GermanyinSGP',\n",
    "#  'mdzulkar9',\n",
    "#  'marzzorella',\n",
    "#  'sabrinaamorenoo',\n",
    "#  'zaobaosg',\n",
    "#  'c4rmenk4ss',\n",
    "#  'restofworld',\n",
    "#  'therosesloves',\n",
    "#  'DeputySecState',\n",
    "#  'moniza_hossain',\n",
    "#  'AtinSingapore00',\n",
    "#  'blxcknicotine',\n",
    "#  'MohanadElshieky',\n",
    "#  'BriPyon',\n",
    "#  'baddanadanabad',\n",
    "#  'MattersMohinga',\n",
    "#  'tisthedamnperry',\n",
    "#  'juswanafeelgood',\n",
    "#  'beyrima',\n",
    "#  'DarcyDs',\n",
    "#  'JusticeMyanmar',\n",
    "#  'minnnnnnnim',\n",
    "#  'daraobien',\n",
    "#  'shurikeygear',\n",
    "#  'sgmelbboi',\n",
    "#  '6yearswithikon',\n",
    "#  'NikkeiAsia',\n",
    "#  'RealRoopii',\n",
    "#  'UN_News_Centre',\n",
    "#  'xinghui_kok',\n",
    "#  'HURFOM',\n",
    "#  'lamkiduad',\n",
    "#  'anandmahindra',\n",
    "#  'wkeaii',\n",
    "#  'RWMaloneMD',\n",
    "#  'sarahrxdriguez',\n",
    "#  'ulat_bulu_bulu',\n",
    "#  'KodaiAIO',\n",
    "#  'Sci_Phile',\n",
    "#  'lioncitysailors']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweet_text', 'tweet_time', 'tweet_id', 'tweet_lang',\n",
       "       'tweet_possibly_sensitive', 'entity_image_url', 'entity_mentions',\n",
       "       'entity_hashtags', 'entity_link_url', 'user_id_x', 'user_name_x',\n",
       "       'user_screenname_x', 'user_friends_count', 'user_followers_count',\n",
       "       'user_verified', 'user_location', 'user_desc', 'user_geo_coding',\n",
       "       'user_geo_tagging', 'user_id_y', 'user_name_y', 'user_screenname_y',\n",
       "       'tweet_enagagement_type', 'replied_to_tweet_id', 'replied_to_user_id',\n",
       "       'replied_to_user_screenname', 'retweeted_tweet_id',\n",
       "       'retweeted_tweet_time', 'retweeted_user_id', 'retweeted_user_name',\n",
       "       'retweeted_user_verified', 'retweeted_user_screenname',\n",
       "       'retweeted_user_geo_coding', 'retweeted_user_geo_coding_type',\n",
       "       'retweeted_retweet_count', 'retweeted_favorite_count',\n",
       "       'quoted_tweet_text', 'quoted_tweet_id', 'quoted_tweet_time',\n",
       "       'quoted_user_id', 'quoted_user_name', 'quoted_user_verified',\n",
       "       'quoted_user_screenname', 'quoted_user_geo_coding',\n",
       "       'quoted_user_geo_coding_type', 'quoted_retweet_count',\n",
       "       'quoted_favorite_count', 'tweet_datetime', 'tweet_date',\n",
       "       'processed_tweet_text', 'processed_quoted_tweet_text',\n",
       "       'tweet_sentiment', 'quoted_tweet_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158949"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sg_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139304, 54)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sg_tweets = sg_tweets[(sg_tweets['retweeted_user_geo_coding'] != 'Singapore|SG')  & (sg_tweets['quoted_user_geo_coding']   != 'Singapore|SG') ]\n",
    "\n",
    "\n",
    "non_sg_tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150061"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_non_verified = sg_tweets[(sg_tweets['user_geo_coding'] == 'Singapore|SG') & (sg_tweets['user_verified'] == False)]\n",
    "len(sg_non_verified)\n",
    "\n",
    "# list(sg_non_verified['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150061"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_verified = sg_tweets[(sg_tweets['user_geo_coding'] == 'Singapore|SG') & (sg_tweets['user_verified'] == True)]\n",
    "len(sg_non_verified)\n",
    "\n",
    "# list(sg_non_verified['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'tweet_text', 'tweet_time', 'tweet_id', 'tweet_lang',\n",
       "       'tweet_possibly_sensitive', 'entity_image_url', 'entity_mentions',\n",
       "       'entity_hashtags', 'entity_link_url', 'user_id_x', 'user_name_x',\n",
       "       'user_screenname_x', 'user_friends_count', 'user_followers_count',\n",
       "       'user_verified', 'user_location', 'user_desc', 'user_geo_coding',\n",
       "       'user_geo_tagging', 'user_id_y', 'user_name_y', 'user_screenname_y',\n",
       "       'tweet_enagagement_type', 'replied_to_tweet_id', 'replied_to_user_id',\n",
       "       'replied_to_user_screenname', 'retweeted_tweet_id',\n",
       "       'retweeted_tweet_time', 'retweeted_user_id', 'retweeted_user_name',\n",
       "       'retweeted_user_verified', 'retweeted_user_screenname',\n",
       "       'retweeted_user_geo_coding', 'retweeted_user_geo_coding_type',\n",
       "       'retweeted_retweet_count', 'retweeted_favorite_count',\n",
       "       'quoted_tweet_text', 'quoted_tweet_id', 'quoted_tweet_time',\n",
       "       'quoted_user_id', 'quoted_user_name', 'quoted_user_verified',\n",
       "       'quoted_user_screenname', 'quoted_user_geo_coding',\n",
       "       'quoted_user_geo_coding_type', 'quoted_retweet_count',\n",
       "       'quoted_favorite_count', 'tweet_datetime', 'tweet_date',\n",
       "       'processed_tweet_text', 'processed_quoted_tweet_text',\n",
       "       'tweet_sentiment', 'quoted_tweet_sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Unknown\n",
       "1         Unknown\n",
       "2         Unknown\n",
       "3         Unknown\n",
       "4         Unknown\n",
       "           ...   \n",
       "158944    Unknown\n",
       "158945    Unknown\n",
       "158946    Unknown\n",
       "158947    Unknown\n",
       "158948    Unknown\n",
       "Name: retweeted_user_geo_coding, Length: 158949, dtype: object"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_tweets['retweeted_user_geo_coding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "myanmar_tweets = sg_tweets[sg_tweets['retweeted_user_geo_coding'] == 'Myanmar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16910, 54)"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sg_tweets_influential = sg_tweets[((sg_tweets['user_screenname_x'].isin(top_50)) & (sg_tweets['user_geo_coding']   != 'Singapore|SG')) | \n",
    "#                                   ((sg_tweets['retweeted_user_screenname'].isin(top_50))  & (sg_tweets['retweeted_user_geo_coding']   != 'Singapore|SG') ) |\n",
    "#                                   ((sg_tweets['quoted_user_screenname'].isin(top_50))  & (sg_tweets['quoted_user_geo_coding']   != 'Singapore|SG') )]\n",
    "# sg_tweets_influential.shape\n",
    "\n",
    "sg_tweets_influential = sg_tweets[((sg_tweets['user_screenname_x'].isin(top_50))) | \n",
    "                                  ((sg_tweets['retweeted_user_screenname'].isin(top_50)) ) |\n",
    "                                  ((sg_tweets['quoted_user_screenname'].isin(top_50)))]\n",
    "sg_tweets_influential.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9770, 54)"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verified \n",
    "sg_tweets_verified = sg_tweets[sg_tweets['user_verified'] == True]\n",
    "sg_tweets_verified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_tweets_negative = sg_tweets[sg_tweets['tweet_sentiment'] == 'negative']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tw_by_time_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mv/c151lb7j7xx6ff_q9_85p_pc0000gn/T/ipykernel_98437/2998094168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtw_by_time_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtw_by_time_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tw_by_time_data' is not defined"
     ]
    }
   ],
   "source": [
    "tw_by_time_data.loc[tw_by_time_data['count'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline \n",
    "\n",
    "# plt.rcParams['figure.figsize'] = [25, 25]\n",
    "# plt.plot(tw_by_time_data['date'], tw_by_time_data['count'])\n",
    "# plt.xticks(tw_by_time_data['date'], tw_by_time_data['date'], rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292,)\n"
     ]
    }
   ],
   "source": [
    "# myanmar_tweets['tweet_text']\n",
    "\n",
    "maynmar_tweets = sg_tweets[(sg_tweets['retweeted_user_geo_coding'] == 'India') &\n",
    "                           (sg_tweets['tweet_text'].notna())\n",
    "                          ]['tweet_text'].unique()#.head(50)\n",
    "print(maynmar_tweets.shape)\n",
    "\n",
    "# maynmar_tweets = [re.sub(\"RT @[A-Z_a-z_0-9:]+\",\"\", txt).strip() for txt in maynmar_tweets ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sg_tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143       delta variant spreads sydney australia widens ...\n",
       "150                       cats changed pandemic home boys *\n",
       "176       media intelligence agency commissioned crowdfu...\n",
       "184       mans huge regret elderly parents covid convinc...\n",
       "230       know difficult play balestier home ground sail...\n",
       "                                ...                        \n",
       "181349                     magnesium supplements help sleep\n",
       "181372    thundery showers mainly northern eastern singa...\n",
       "181380                hanois tiny balconies refuge lockdown\n",
       "181392          morning briefing stories straits times sept\n",
       "181394    silicon valleys billionaires want hack ageing ...\n",
       "Name: processed_tweet_text, Length: 5395, dtype: object"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_influential_users_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "maynmar_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5395/5395 [00:00<00:00, 535478.96it/s]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maynmar_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, getcwd\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # complaints_text = list(df['processed'])\n",
    "\n",
    "# COUNTRY = 'Singapore'\n",
    "# maynmar_tweets = sg_tweets[(sg_tweets['retweeted_user_geo_coding'] == COUNTRY) &\n",
    "#                            (sg_tweets['processed_tweet_text'].notna())\n",
    "#                           ]['processed_tweet_text'].unique()#.head(50)\n",
    "\n",
    "# # join all documents in corpus\n",
    "# text = \" \".join(list(maynmar_tweets))\n",
    "# # print(\"Complaints received\")\n",
    "# # print(len(complaints_text))\n",
    "\n",
    "# # d = getcwd()\n",
    "# # mask = np.array(Image.open(path.join(d, \"thumbs-down.png\")))\n",
    "\n",
    "# # STOPWORDS.add(\"singapore\")\n",
    "# # STOPWORDS.add(\"covid\")\n",
    "# # STOPWORDS.add(\"vaccine\")\n",
    "# # STOPWORDS.add(\"vaccination\")\n",
    "# # # # TODO exclude name of all banks here\n",
    "# # STOPWORDS.add(\"waste\")\n",
    "# # STOPWORDS.add(\"fargo\")\n",
    "\n",
    "# STOPWORDS.update([COUNTRY, 'chinese', 'singapore', 'covid', 'vaccine', 'vaccination', 'vaccinated'])\n",
    "\n",
    "# wc = WordCloud(\n",
    "#     background_color=\"white\",\n",
    "#     stopwords=STOPWORDS,\n",
    "#     max_words=1000,\n",
    "#     # mask=mask,\n",
    "#     max_font_size=90,\n",
    "#     random_state=42,\n",
    "#     contour_width=1,\n",
    "#     contour_color=\"black\",\n",
    "# )\n",
    "# wc.generate(text)\n",
    "# print(\"**\", type(wc))\n",
    "# import matplotlib.pyplot as plt\n",
    "# # create wordcloud shape from image\n",
    "# plt.figure(figsize=[8, 8])\n",
    "# # plt.imshow(wc.recolor(), interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# #wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "# #plt.figure()\n",
    "# plt.imshow(wc, interpolation=\"bilinear\")\n",
    "# #plt.axis(\"off\")\n",
    "# #plt.imshow()\n",
    "# # print(type(STOPWORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# influential_users\n",
    "influential_users = pd.read_csv(\n",
    "    'data/output/influencers/top_users.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_influential_users = influential_users[influential_users['user_geo_coding'] == 'India']['user_screenname']\n",
    "country_influential_users_tweets = sg_tweets[(sg_tweets['user_screenname_x'].isin(country_influential_users)) | sg_tweets['retweeted_user_screenname'] \\\n",
    "          .isin(country_influential_users)]#['']\n",
    "\n",
    "country_influential_users_tweets = country_influential_users_tweets['processed_tweet_text']\n",
    "# print(country_influential_users_tweets.shape)\n",
    "# country_influential_users\n",
    "# list(country_influential_users_tweets)\n",
    "# country_influential_users_tweets\n",
    "\n",
    "country_influential_users_tweets.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 6114.15it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_tweets = []\n",
    "for tw in tqdm(country_influential_users_tweets):\n",
    "    try:\n",
    "        tokenized_tweets.append(tw.split(' '))\n",
    "    except Exception as e:\n",
    "        pass\n",
    "#         print(e)\n",
    "\n",
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(tokenized_tweets, min_count=2, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[tokenized_tweets], threshold=50)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "# print(bigram_mod[tokenized_tweets[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(tokenized_tweets)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "# data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# [[(id2word[id], freq) for id, freq in cp] for cp in corpus[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=10,\n",
    "                                           update_every=0,\n",
    "#                                            chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n",
      "/Users/anshu/opt/anaconda3/lib/python3.8/site-packages/past/builtins/misc.py:45: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  from imp import reload\n"
     ]
    }
   ],
   "source": [
    "# pyLDAvis.enable_notebook()\n",
    "# vis = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "# vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['singapore', 'story', 'company', 'mohan', 'paywalled', 'link', 'probe', 'bharat', 'bolsonaro', 'centre'], ['company', 'singapore', 'story', 'mohan', 'paywalled', 'link', 'probe', 'bharat', 'bolsonaro', 'centre'], ['singapore', 'story', 'company', 'mohan', 'paywalled', 'link', 'probe', 'bharat', 'bolsonaro', 'centre'], ['singapore', 'story', 'company', 'mohan', 'paywalled', 'link', 'probe', 'bharat', 'bolsonaro', 'centre'], ['singapore', 'story', 'company', 'mohan', 'paywalled', 'link', 'probe', 'bharat', 'bolsonaro', 'centre']]\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string, strip_punctuation,strip_numeric\n",
    "\n",
    "lda_topics = lda_model.show_topics()\n",
    "\n",
    "topics = []\n",
    "filters = [lambda x: x.lower(), strip_punctuation, strip_numeric]\n",
    "\n",
    "for topic in lda_topics:\n",
    "#     print(topic)\n",
    "    topics.append(preprocess_string(topic[1], filters))\n",
    "\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.041*\"country\" + 0.028*\"world\" + 0.015*\"police\" + 0.015*\"australian\" + 0.015*\"far\" + 0.015*\"crisis\" + 0.015*\"singapore\" + 0.015*\"response\" + 0.015*\"meeting\" + 0.015*\"lockdown\"\n",
      "0.046*\"vaccinated\" + 0.017*\"young\" + 0.017*\"delta\" + 0.017*\"test\" + 0.017*\"effort\" + 0.002*\"people\" + 0.002*\"day\" + 0.002*\"progress\" + 0.002*\"speak\" + 0.002*\"world\"\n",
      "0.042*\"chinese\" + 0.028*\"key\" + 0.015*\"delta\" + 0.015*\"open\" + 0.015*\"food\" + 0.015*\"peace\" + 0.015*\"embassy\" + 0.015*\"time\" + 0.015*\"low\" + 0.015*\"country\"\n",
      "0.035*\"state\" + 0.035*\"today\" + 0.024*\"fully\" + 0.024*\"lockdown\" + 0.024*\"https\" + 0.024*\"dose\" + 0.024*\"cross\" + 0.024*\"help\" + 0.013*\"office\" + 0.013*\"world\"\n",
      "0.032*\"way\" + 0.017*\"precaution\" + 0.017*\"death\" + 0.017*\"include\" + 0.002*\"progress\" + 0.002*\"vaccinated\" + 0.002*\"people\" + 0.002*\"speak\" + 0.002*\"chinese\" + 0.002*\"arrive\"\n",
      "0.073*\"people\" + 0.049*\"day\" + 0.025*\"new\" + 0.013*\"vaccinated\" + 0.013*\"time\" + 0.013*\"pfizer\" + 0.013*\"shot\" + 0.013*\"stand\" + 0.013*\"hospital\" + 0.013*\"member\"\n",
      "0.030*\"arrive\" + 0.030*\"speak\" + 0.016*\"open\" + 0.016*\"million\" + 0.016*\"agency\" + 0.016*\"group\" + 0.016*\"new\" + 0.002*\"vaccinated\" + 0.002*\"day\" + 0.002*\"people\"\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, lda_model.num_topics-1):\n",
    "    print(lda_model.print_topic(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
